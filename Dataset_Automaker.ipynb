{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b02074fb-7835-4105-8ecf-bd6a658a617d",
      "metadata": {
        "id": "b02074fb-7835-4105-8ecf-bd6a658a617d"
      },
      "source": [
        "# LoRA Dataset Automaker\n",
        "\n",
        "Created by *Maximax67*\n",
        "\n",
        "*Civitai: [Maximax67](https://civitai.com/user/Maximax67)*  \n",
        "*Telegram: [@Maximax67](https://t.me/Maximax67)*  \n",
        "*Github: [Maximax67](https://github.com/Maximax67)*  \n",
        "*Gmail: maximax6767@gmail.com*  \n",
        "\n",
        "I use some code from this [Dataset Maker colab](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) colab for deleting duplicate images and auto-tagging them (it uses [kohya-ss scripts](https://github.com/kohya-ss/sd-scripts)). Also, I use [yolov5_anime](https://github.com/zymk9/yolov5_anime.git) models by zymk9 for detecting faces on images. I trained a model that calculates the similarity between anime faces. The dataset of images is not very large, and the model may give incorrect predictions for some characters.\n",
        "\n",
        "You can run this notebook locally. Tested with laptop Nvidia RTX 3050 4 GB, 55W GPU. But you can still run it locally without GPU.\n",
        "\n",
        "<hr>\n",
        "\n",
        "üü• - Important cell! You need to run it!<br>\n",
        "üü® - It is not necessary to run this cell if you are working on a past saved project (locally or on Google drive if colab).<br>\n",
        "üü© - Optional cell."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1377bb3e",
      "metadata": {
        "id": "1377bb3e"
      },
      "source": [
        "![image.svg](./image.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a229aead-133b-4dd3-b806-12cdbecd2313",
      "metadata": {
        "id": "a229aead-133b-4dd3-b806-12cdbecd2313"
      },
      "source": [
        "## **1Ô∏è‚É£üü• Define global project settings, install and include all libraries, define paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f150e0-a7c0-48da-96ca-4a611f1b5e05",
      "metadata": {
        "cellView": "form",
        "id": "80f150e0-a7c0-48da-96ca-4a611f1b5e05"
      },
      "outputs": [],
      "source": [
        "# @title 1 Global project setting\n",
        "\n",
        "# @markdown Select if you are working in colab!\n",
        "\n",
        "# IMPORTANT! IF YOU USE THIS NOTEBOOK LOCALLY, PASTE \"Local\" IN RUNTIME_TYPE!\n",
        "runtime_type = \"Colab\" # @param [\"Colab\", \"Colab no gpu (only scrapping)\", \"Local\"]\n",
        "\n",
        "# If you are working locally and don't want to type all strings in variables set this variable to True.\n",
        "# The most important fields will be shown as inputs!\n",
        "ask_using_inputs = False\n",
        "\n",
        "if runtime_type == \"Colab\":\n",
        "    colab = True\n",
        "    colab_no_gpu = False\n",
        "elif runtime_type == \"Colab no gpu (only scrapping)\":\n",
        "    colab = True\n",
        "    colab_no_gpu = True\n",
        "elif runtime_type == \"Local\":\n",
        "    colab = False\n",
        "    colab_no_gpu = False\n",
        "else:\n",
        "    print(\"ERROR! Wrong runtime type. Using default local runtime!\")\n",
        "    colab = False\n",
        "    colab_no_gpu = False\n",
        "\n",
        "if not colab and colab_no_gpu:\n",
        "    colab_no_gpu = False\n",
        "    print(\"If you are not using colab (colab = False), you don't need to select colab_no_gpu!\")\n",
        "\n",
        "\n",
        "# @markdown Select \"Colab only scrapping\" if you are working in colab and want only to scrape images (use no GPU runtime)! It will not install and import libraries required for 3-5 sections.\n",
        "\n",
        "# @markdown You can use yolov_5x model istead of yolov_5s. It works slower.\n",
        "# @markdown The performances are comparable. However, with a higher confidence threshold, yolov5x can significantly outperform yolov5s.\n",
        "# @markdown For more details [read here](https://github.com/zymk9/yolov5_anime/tree/master).\n",
        "use_yolov_5x_model = False #@param {type:\"boolean\"}\n",
        "\n",
        "# @markdown If enabled, yolov 5 and similarity models will be downloadede to the working dir (you will define it in 1.5 cell), instead of the current location.\n",
        "download_models_to_working_dir = False #@param {type:\"boolean\"}\n",
        "\n",
        "if colab:\n",
        "    from google.colab.output import clear as clear_output\n",
        "    from google.colab import files\n",
        "else:\n",
        "    from IPython.display import clear_output\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2767033a-eea2-442b-bb75-1f13138241e6",
      "metadata": {
        "cellView": "form",
        "id": "2767033a-eea2-442b-bb75-1f13138241e6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# @title 2 Install libraries\n",
        "# @markdown If you are working locally, you may not run this cell if you have already run it once.\n",
        "!pip install -q requests beautifulsoup4 regex tqdm\n",
        "\n",
        "if not colab_no_gpu:\n",
        "    import os\n",
        "    root_directory = os.getcwd()\n",
        "\n",
        "    if not os.path.exists(os.path.join(root_directory, \"yolov5\")):\n",
        "        !git clone \"https://github.com/ultralytics/yolov5\"\n",
        "        os.chdir(\"yolov5\")\n",
        "        !pip -q install -r requirements.txt\n",
        "        os.chdir(root_directory)\n",
        "\n",
        "    if not os.path.exists(os.path.join(root_directory, \"kohya-trainer\")):\n",
        "        !git clone \"https://github.com/Linaqruf/kohya-trainer\"\n",
        "        os.chdir(\"kohya-trainer\")\n",
        "        !pip -q install -r requirements.txt\n",
        "        os.chdir(root_directory)\n",
        "\n",
        "    !pip install -q opencv-python\n",
        "    !pip install -q Pillow\n",
        "    !pip install -q torch torchvision scikit-learn\n",
        "    !pip install -q fiftyone ftfy\n",
        "\n",
        "    if colab:\n",
        "        !pip install -q fiftyone-db-ubuntu2204\n",
        "\n",
        "clear_output()\n",
        "print(\"Installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7abe8e2f-9f92-4e99-84d2-4d84a7dfca40",
      "metadata": {
        "cellView": "form",
        "id": "7abe8e2f-9f92-4e99-84d2-4d84a7dfca40"
      },
      "outputs": [],
      "source": [
        "# @title 3 Import libraries\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import quote\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "import concurrent.futures\n",
        "import threading\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "if not colab_no_gpu:\n",
        "    import sys\n",
        "    import random\n",
        "    import pickle\n",
        "    from collections import Counter\n",
        "\n",
        "    import subprocess\n",
        "\n",
        "    import numpy as np\n",
        "    import fiftyone as fo\n",
        "    import fiftyone.zoo as foz\n",
        "    from fiftyone import ViewField as VF\n",
        "    from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
        "\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    from torchvision import models, transforms\n",
        "\n",
        "    from PIL import Image\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    %matplotlib inline\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        print(\"Using cuda GPU\")\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "        print(\"torch.cuda is NOT available! Using CPU!\")\n",
        "\n",
        "print(\"Imported!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1974a5b8-e49d-4946-8be1-02b90a524e1f",
      "metadata": {
        "cellView": "form",
        "id": "1974a5b8-e49d-4946-8be1-02b90a524e1f"
      },
      "outputs": [],
      "source": [
        "# @title 4 üü© Connect to google drive (Optional)\n",
        "# @markdown Only if you're in a colab! If you want to save everything to google drive or want to export the dataset to Google drive.\n",
        "if colab:\n",
        "    from google.colab import drive\n",
        "    print(\"Connecting to Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Connected!\")\n",
        "else:\n",
        "    print(\"You are not in a colab! If it's wrong, please select colab runtime type at the first cell!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c863d003-db50-49a4-a2de-7a09a370e07f",
      "metadata": {
        "cellView": "form",
        "id": "c863d003-db50-49a4-a2de-7a09a370e07f"
      },
      "outputs": [],
      "source": [
        "# @title 5 Define path variables\n",
        "\n",
        "# @markdown Enter your project name. It will create a folder with this name inside your working dir.\n",
        "# @markdown You can change the working dir to <b>drive/My Drive/</b> if you want to save all data in your google drive.\n",
        "# @markdown If you run this notebook locally, change working_dir to where you want to save all data.\n",
        "project_name = \"\" #@param {type:\"string\"}\n",
        "working_dir = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "supported_image_formats = ('.jpg', '.png', '.jpeg')\n",
        "\n",
        "if ask_using_inputs:\n",
        "    project_name = input(\"Enter project name:\")\n",
        "    working_dir = input(\"Input working dir (empty input means './'):\")\n",
        "\n",
        "if not project_name:\n",
        "    project_name = \"default\"\n",
        "\n",
        "if not working_dir:\n",
        "    working_dir = \"./\"\n",
        "\n",
        "def create_valid_folder_name(name):\n",
        "    folder_name = name.replace(\" \", \"_\")\n",
        "    folder_name = re.sub(r'[^\\w.-]', '', folder_name)\n",
        "\n",
        "    return folder_name\n",
        "\n",
        "project_name = create_valid_folder_name(project_name)\n",
        "working_dir = os.path.abspath(working_dir)\n",
        "\n",
        "project_dir = os.path.join(working_dir, project_name)\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "image_scrape_path = os.path.join(project_dir, \"scrapped\")\n",
        "filtered_dir = os.path.join(project_dir, \"filtered\")\n",
        "\n",
        "faces_dir = os.path.join(project_dir, \"faces\")\n",
        "\n",
        "example_folder = os.path.join(project_dir, \"examples\")\n",
        "\n",
        "result_dir = os.path.join(project_dir, \"result\")\n",
        "\n",
        "model_dir_path = working_dir if download_models_to_working_dir else os.path.abspath(os.getcwd())\n",
        "\n",
        "if use_yolov_5x_model:\n",
        "    yolov_model_path = os.path.join(model_dir_path, \"yolov5x_anime.pt\")\n",
        "else:\n",
        "    yolov_model_path = os.path.join(model_dir_path, \"yolov5s_anime.pt\")\n",
        "\n",
        "similarity_model_path = os.path.join(model_dir_path, \"similarity.pt\")\n",
        "\n",
        "print(\"Project name:\".ljust(14), project_name)\n",
        "print(\"Working dir:\".ljust(14), working_dir)\n",
        "\n",
        "print(\"\\n\\tProject structure:\")\n",
        "print(\"Image scrape path\".ljust(30), image_scrape_path)\n",
        "print(\"Filtered from duplicates dir\".ljust(30), filtered_dir)\n",
        "print(\"Detected faces dir\".ljust(30), faces_dir)\n",
        "print(\"Example dir\".ljust(30), example_folder)\n",
        "print(\"Result dir\".ljust(30), result_dir)\n",
        "print(\"-\" * 70)\n",
        "print(\"Face detection model\".ljust(30), yolov_model_path)\n",
        "print(\"Face similarity model\".ljust(30), similarity_model_path)\n",
        "\n",
        "print(\"\\nSupported image formats:\", *supported_image_formats)\n",
        "\n",
        "# This functions will be used in multiple sections. I decided to put them here.\n",
        "def delete_contents_of_dir(directory):\n",
        "    for item in os.listdir(directory):\n",
        "        item_path = os.path.join(directory, item)\n",
        "        if os.path.isfile(item_path):\n",
        "            os.remove(item_path)\n",
        "        elif os.path.isdir(item_path):\n",
        "            shutil.rmtree(item_path)\n",
        "\n",
        "if not colab:\n",
        "    # When I run python scripts like !python, I don't see their outputs locally in jupyter notebook.\n",
        "    # So, I came up with this solution.\n",
        "    def script_runner(script):\n",
        "        process = subprocess.Popen(\n",
        "            script,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        while True:\n",
        "            output = process.stdout.readline()\n",
        "            if output == '' and process.poll() is not None:\n",
        "                break\n",
        "            if output:\n",
        "                print(output.strip())\n",
        "                sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b494e67-2ae5-4f8b-9e2a-8d89d65d5bee",
      "metadata": {
        "cellView": "form",
        "id": "0b494e67-2ae5-4f8b-9e2a-8d89d65d5bee"
      },
      "outputs": [],
      "source": [
        "# @title 6 Set character name\n",
        "\n",
        "# @markdown It will make a subfolder inside your result folder. You can make as many characters as you want from once downloaded screencaps and detected faces.\n",
        "# @markdown Just rerun this cell to change character!\n",
        "character_name = \"\" # @param {type:\"string\"}\n",
        "\n",
        "if ask_using_inputs:\n",
        "    character_name = input(\"Enter character name:\")\n",
        "\n",
        "if not character_name:\n",
        "    character_name = \"default\"\n",
        "\n",
        "character_name = create_valid_folder_name(character_name)\n",
        "\n",
        "example_character = os.path.join(example_folder, character_name)\n",
        "example_faces_dir = os.path.join(example_folder, character_name, \"faces\")\n",
        "example_orig_img_dir = os.path.join(example_folder, character_name, \"images\")\n",
        "similar_faces_dir = os.path.join(project_dir, \"similar_faces\", character_name)\n",
        "character_results = os.path.join(result_dir, character_name)\n",
        "\n",
        "print(\"Done! Character name is:\", character_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae60d041-1767-41ef-90fe-5d971ea72e7d",
      "metadata": {
        "id": "ae60d041-1767-41ef-90fe-5d971ea72e7d"
      },
      "source": [
        "## **2Ô∏è‚É£üü® Download screencaps (takes the most time)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb39990-9bae-406c-81f0-a3d224707596",
      "metadata": {
        "cellView": "form",
        "id": "4eb39990-9bae-406c-81f0-a3d224707596",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# @title 1 Search your anime / movie / tv\n",
        "# @markdown Enter your anime / film / cartoon / tv name. Important! This dataset maker can only detect anime and some cartoon faces. It will not work with real humans.\n",
        "# @markdown Maybe I make this in the future.\n",
        "prompt = \"Demon Slayer\" #@param {type:\"string\"}\n",
        "\n",
        "if ask_using_inputs:\n",
        "    prompt = input(\"Enter search prompt:\")\n",
        "\n",
        "# @markdown You can configure your search parameters, but I recommend leaving all turned on.\n",
        "search_anime = True  #@param {type:\"boolean\"}\n",
        "search_movies = True #@param {type:\"boolean\"}\n",
        "search_tv = True     #@param {type:\"boolean\"}\n",
        "\n",
        "def fetch_results(prompt, search_anime=True, search_movies=True, search_tv=True):\n",
        "    if not search_anime and not search_movies and not search_tv:\n",
        "        print(\"Error! Nothing to search! One of three categories should be selected!\")\n",
        "        return None\n",
        "\n",
        "    url = \"https://fancaps.net/search.php?q=\" + quote(prompt)\n",
        "\n",
        "    if search_movies:\n",
        "        url += \"&MoviesCB=Movies\"\n",
        "\n",
        "    if search_tv:\n",
        "        url += \"&TVCB=TV\"\n",
        "\n",
        "    if search_anime:\n",
        "        url += \"&animeCB=Anime\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(\"Failed to fetch the website!\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    results_content = soup.find_all(\"div\", class_=\"single_post_content\")[1].find_all(\"table\")\n",
        "    return results_content\n",
        "\n",
        "def parse_website(prompt, search_anime=True, search_movies=True, search_tv=True):\n",
        "    results_content = fetch_results(prompt, search_anime, search_movies, search_tv)\n",
        "\n",
        "    if not results_content:\n",
        "        return None\n",
        "\n",
        "    categories = []\n",
        "    if search_movies:\n",
        "        categories.append(\"Movies\")\n",
        "    if search_tv:\n",
        "        categories.append(\"TV\")\n",
        "    if search_anime:\n",
        "        categories.append(\"Anime\")\n",
        "\n",
        "    results = {category: [] for category in categories}\n",
        "\n",
        "    counter = 1\n",
        "\n",
        "    for i, content in enumerate(results_content):\n",
        "        trs = content.find_all('tr')\n",
        "        for tr in trs:\n",
        "            a_element = tr.find('h4').find('a')\n",
        "            link = a_element.get('href')\n",
        "            name = a_element.text\n",
        "            results[categories[i]].append((name, link, counter))\n",
        "            counter += 1\n",
        "\n",
        "    return results\n",
        "\n",
        "def print_results(results):\n",
        "    if not results:\n",
        "        print(\"No results to display.\")\n",
        "        return\n",
        "\n",
        "    for category, items in results.items():\n",
        "        print(f\"{category} ({len(items)}):\")\n",
        "        if not items:\n",
        "            print(\"  No items found.\")\n",
        "            continue\n",
        "        for i, item in enumerate(items, 1):\n",
        "            print(f\"  {item[2]}. {item[0]}\")\n",
        "\n",
        "search_results = parse_website(prompt, search_anime, search_movies, search_tv)\n",
        "print(\"\\tResults for\", prompt)\n",
        "print_results(search_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f524b2a-9c3b-4b4e-a173-f5d1b7616a20",
      "metadata": {
        "cellView": "form",
        "id": "6f524b2a-9c3b-4b4e-a173-f5d1b7616a20"
      },
      "outputs": [],
      "source": [
        "# @title 2 Choose what you need from the list\n",
        "# @markdown Write selected item numbers separated by a comma (you can use the '-' range). For example 1,2,5-10\n",
        "selected_input = \"1\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown If you choose tv or anime, it may contain episodes/series.\n",
        "# @markdown If you turn this on, you can select which episodes/series do you want to download for each selected item in the next cell.\n",
        "ask_for_episodes = True #@param {type:\"boolean\"}\n",
        "\n",
        "if ask_using_inputs:\n",
        "    selected_input = input(\"Write selected indices separated by comma (you can use '-' range):\")\n",
        "\n",
        "def parse_input_indices(input_string):\n",
        "    indices = []\n",
        "    ranges = input_string.split(',')\n",
        "\n",
        "    for r in ranges:\n",
        "        r = r.strip()\n",
        "        if not r:\n",
        "            continue  # Skip empty parts\n",
        "\n",
        "        if '-' in r:\n",
        "            range_parts = r.split('-')\n",
        "            if len(range_parts) != 2:\n",
        "                print(f\"Invalid range format: {r}\")\n",
        "                return None\n",
        "\n",
        "            start_str, end_str = map(str.strip, range_parts)\n",
        "            if not start_str.isdigit() or not end_str.isdigit():\n",
        "                print(f\"Invalid range values: {r}\")\n",
        "                return None\n",
        "\n",
        "            start, end = int(start_str), int(end_str)\n",
        "            indices.extend(range(start, end + 1))\n",
        "        else:\n",
        "            if not r.isdigit():\n",
        "                print(f\"Invalid index value: {r}\")\n",
        "                return None\n",
        "\n",
        "            indices.append(int(r))\n",
        "\n",
        "    return indices\n",
        "\n",
        "def select_items(results, selected_indices):\n",
        "    selected = {}\n",
        "\n",
        "    for category, items in results.items():\n",
        "        selected_items = []\n",
        "        for item in items:\n",
        "            if item[2] in selected_indices:\n",
        "                selected_items.append(item)\n",
        "        selected[category] = selected_items\n",
        "\n",
        "    return selected\n",
        "\n",
        "def print_selected(selected):\n",
        "    if not selected:\n",
        "        print(\"Nothing selected!!!\")\n",
        "        return\n",
        "\n",
        "    print(\"\\tSelected:\")\n",
        "    for category, items in selected.items():\n",
        "        print(f\"{category} ({len(items)}):\")\n",
        "        if not items:\n",
        "            print(\"  No items selected!\")\n",
        "            continue\n",
        "        for item in items:\n",
        "            print(f\"  {item[2]}. {item[0]}\")\n",
        "\n",
        "if not selected_input:\n",
        "    print(\"ERROR! Nothing selected!\")\n",
        "else:\n",
        "    selected_list = parse_input_indices(selected_input)\n",
        "\n",
        "if selected_list:\n",
        "    selected_results = select_items(search_results, selected_list)\n",
        "    print_selected(selected_results)\n",
        "\n",
        "    series = False\n",
        "    for category, items in selected_results.items():\n",
        "        if items and (category == \"TV\" or category == \"Anime\"):\n",
        "            series = True\n",
        "            break\n",
        "\n",
        "    if series and not ask_for_episodes:\n",
        "        print(\"\\nWARNING! Some of your selected items may contain series/episodes!\")\n",
        "        if ask_using_inputs:\n",
        "            print(\"If you don't want to download them fully, enter 'Y' and I will ask you what series/episodes to download in the next cell! Other inputs will mean 'no'!\")\n",
        "            ask_input = input(\"\")\n",
        "            if ask_input == 'Y' or ask_input == 'y':\n",
        "                ask_for_episodes = True\n",
        "        else:\n",
        "            print(\"If you don't want to download them fully, mark the ask_for_episodes box and rerun this cell.\")\n",
        "            print(\"I will ask you what series/episodes to download in the next cell!\")\n",
        "\n",
        "else:\n",
        "    print(\"Run this cell again!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01d9d99f-952f-4d9f-b683-d3ac9efc4cb2",
      "metadata": {
        "cellView": "form",
        "editable": true,
        "id": "01d9d99f-952f-4d9f-b683-d3ac9efc4cb2",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# @title 3 Download screencaps\n",
        "\n",
        "# @markdown Average download time is 5,5 images per second! The average anime episode is 800 images. If your anime has 20 episodes, the download time will be 48 minutes!\n",
        "# @markdown If your anime is big, sometimes it's better to make a working dir in google drive and select no GPU runtime for scrapping, switch to GPU runtime, and go to the next cells.\n",
        "# @markdown Or you can scrape images with no GPU runtime, download your project as zip file (see 6.2 cell), switch to GPU runtime, upload your zip file to colab, and unzip it (see 7.1 cell).\n",
        "\n",
        "# @markdown It will make dirs in your scrapped dir for each downloaded episode. Doesn't matter if you don't want to use these screencaps somewhere else.\n",
        "make_dirs_for_episodes = True #@param {type:\"boolean\"}\n",
        "\n",
        "# @markdown If you want to delete previously downloaded images in the folder (if you run this cell before), select this:\n",
        "delete_previous_downloaded_images = False # @param {type:\"boolean\"}\n",
        "\n",
        "os.makedirs(image_scrape_path, exist_ok=True)\n",
        "\n",
        "if delete_previous_downloaded_images:\n",
        "    delete_contents_of_dir(image_scrape_path)\n",
        "\n",
        "# @markdown Download params:\n",
        "timeout = 5 #@param {type:\"number\"}\n",
        "max_retries = 3 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "def get_string_after_last_slash(string):\n",
        "    last_index = string.rfind('/')\n",
        "    if last_index != -1:\n",
        "        return string[last_index + 1:]\n",
        "\n",
        "    return string\n",
        "\n",
        "\n",
        "def fetch_episode_images_names(url):\n",
        "    images_names = []\n",
        "\n",
        "    continue_search = True\n",
        "    page = 1\n",
        "    while continue_search:\n",
        "        fetch_url = url + \"&page=\" + str(page)\n",
        "        response = requests.get(fetch_url)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(\"Failed to fetch the website!\")\n",
        "            break\n",
        "\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "        post_area = soup.find('section', {'id': 'contentbody'}).find('div', {'class': 'single_post_area'})\n",
        "\n",
        "        images = []\n",
        "        episodes_section = post_area.find(lambda tag: tag.name == 'div' and ('Episode Screencaps' in tag.text or 'Episode Images' in tag.text))\n",
        "        next_sibling = episodes_section.find_next_sibling('div', {'class': 'row'})\n",
        "        while next_sibling:\n",
        "            found_images = next_sibling.find_all('img', {'class': 'imageFade'})\n",
        "            for found_image in found_images:\n",
        "                images.append(found_image.get('src'))\n",
        "            next_sibling = next_sibling.find_next_sibling('div', {'class': 'row'})\n",
        "\n",
        "        page += 1\n",
        "\n",
        "        if images:\n",
        "            for src in images:\n",
        "                name = get_string_after_last_slash(src)\n",
        "                images_names.append(name)\n",
        "\n",
        "            next_page_url = post_area.select_one('ul.pagination li:last-child a').get('href')\n",
        "            if next_page_url == '#':\n",
        "                continue_search = False\n",
        "        else:\n",
        "            continue_search = False\n",
        "\n",
        "\n",
        "    return images_names\n",
        "\n",
        "\n",
        "def fetch_movies_images_names(url):\n",
        "    images_names = []\n",
        "\n",
        "    continue_search = True\n",
        "    page = 1\n",
        "    while continue_search:\n",
        "        fetch_url = url + \"&page=\" + str(page)\n",
        "        response = requests.get(fetch_url)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(\"Failed to fetch the website!\")\n",
        "            break\n",
        "\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "        images_bar = soup.find('section', {'id': 'contentbody'}).find('div', {'class': 'middle_bar'})\n",
        "\n",
        "        images = []\n",
        "        title = images_bar.find('h2', {'class': 'post_title'})\n",
        "        images_div = title.find_next_sibling('div', {'class': ''})\n",
        "        if images_div:\n",
        "            found_images = images_div.find_all('img', {'class': 'imageFade'})\n",
        "            for found_image in found_images:\n",
        "                images.append(found_image.get('src'))\n",
        "\n",
        "        page += 1\n",
        "\n",
        "        if images:\n",
        "            for src in images:\n",
        "                name = get_string_after_last_slash(src)\n",
        "                images_names.append(name)\n",
        "\n",
        "            next_page_url = images_bar.select_one('ul.pagination li:last-child a').get('href')\n",
        "            if next_page_url == '#':\n",
        "                continue_search = False\n",
        "\n",
        "        else:\n",
        "            continue_search = False\n",
        "\n",
        "\n",
        "    return images_names\n",
        "\n",
        "\n",
        "def fetch_episodes_links(url):\n",
        "    episodes_links = []\n",
        "\n",
        "    continue_search = True\n",
        "    page = 1\n",
        "    while continue_search:\n",
        "        fetch_url = url + \"&page=\" + str(page)\n",
        "        response = requests.get(fetch_url)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(\"Failed to fetch the website!\")\n",
        "            break\n",
        "\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "        contentbody_section = soup.find('section', {'id': 'contentbody'})\n",
        "        target_links = contentbody_section.find_all('a', {'class': 'btn btn-block'})\n",
        "        page += 1\n",
        "\n",
        "        if target_links:\n",
        "            for a in target_links:\n",
        "                link = a.get('href')\n",
        "                if link.startswith('/'):\n",
        "                    link = \"https://fancaps.net\" + link\n",
        "\n",
        "                episodes_links.append(link)\n",
        "        else:\n",
        "            continue_search = False\n",
        "\n",
        "    return episodes_links\n",
        "\n",
        "\n",
        "def download_single_image(url, path, name, timeout=10, max_retries=3):\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            response = requests.get(url, stream=True, timeout=timeout)\n",
        "            if response.status_code == 200:\n",
        "                file_path = os.path.join(path, name)\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(16384):\n",
        "                        f.write(chunk)\n",
        "                break  # Successful download, exit loop\n",
        "            else:\n",
        "                print(f\"Failed to download image {name} - Status Code: {response.status_code}\")\n",
        "        except requests.exceptions.ReadTimeout:\n",
        "            retries += 1\n",
        "            print(f\"Read timeout occurred while downloading image {name}. Retrying ({retries}/{max_retries})...\")\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading image {name}: {e}\")\n",
        "    else:\n",
        "        # If max_retries reached and the image is partially downloaded, delete the partially downloaded file\n",
        "        file_path = os.path.join(path, name)\n",
        "        if os.path.exists(file_path):\n",
        "            os.remove(file_path)\n",
        "            print(f\"Deleted partially downloaded file: {file_path}\")\n",
        "\n",
        "\n",
        "def download_images_fancaps(names, path, section, timeout=10, max_retries=3):\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    total_images = len(names)\n",
        "    lock = threading.Lock()\n",
        "\n",
        "    def update_progress():\n",
        "        with lock:\n",
        "            pbar.update(1)\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for name in names:\n",
        "            try:\n",
        "                url = \"https://cdni.fancaps.net/file/fancaps-\" + section + \"images/\" + name\n",
        "                future = executor.submit(download_single_image, url, path, name, timeout, max_retries)\n",
        "                future.add_done_callback(lambda _: update_progress())\n",
        "                futures.append(future)\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"Error! {e}\")\n",
        "\n",
        "        with tqdm(total=total_images) as pbar:\n",
        "            for future in concurrent.futures.as_completed(futures):\n",
        "                future.result()\n",
        "\n",
        "def ask_for_episodes_to_download(n_episodes):\n",
        "    print(\"\\nWhat series/episodes to download (separated by comma, you can use  the '-' range, empty input means to download all):\")\n",
        "    episodes_to_download_list = []\n",
        "\n",
        "    while not episodes_to_download_list:\n",
        "        episodes_to_download_input = input()\n",
        "\n",
        "        if not episodes_to_download_input:\n",
        "            episodes_to_download_list = range(1, n_episodes + 1)\n",
        "            print(\"Downloading all!\")\n",
        "        else:\n",
        "            episodes_to_download_list = parse_input_indices(episodes_to_download_input)\n",
        "            if not episodes_to_download_list:\n",
        "                print(\"Input again!\")\n",
        "\n",
        "    return episodes_to_download_list\n",
        "\n",
        "def fancaps_scrapper(url, path, ask_for_episodes=False, timeout=10, max_retries=3, dirs_for_episodes=True):\n",
        "    if \"/movies/\" in url:\n",
        "        print(\"Fetching images names...\")\n",
        "        names = fetch_movies_images_names(url)\n",
        "        print(\"Total %d images. Downloading...\" % len(names))\n",
        "        download_images_fancaps(names, path, \"movie\")\n",
        "        print()\n",
        "    else:\n",
        "        if \"/anime/\" in url:\n",
        "            section = \"anime\"\n",
        "        elif \"/tv/\" in url:\n",
        "            section = \"tv\"\n",
        "        else:\n",
        "            print(\"Error! Invalid url!\")\n",
        "            return\n",
        "\n",
        "        print(\"Fetching episodes links\")\n",
        "        links = fetch_episodes_links(url)\n",
        "        print(\"Founded %d episodes\" % len(links))\n",
        "\n",
        "        episodes_to_download = []\n",
        "\n",
        "        if ask_for_episodes:\n",
        "            episodes_to_download = ask_for_episodes_to_download(len(links))\n",
        "        else:\n",
        "            episodes_to_download = range(1, len(links) + 1)\n",
        "\n",
        "        for i, link in enumerate(links, 1):\n",
        "            if i in episodes_to_download:\n",
        "                print(\"\\nEpisode %d\" % i, end='')\n",
        "                names = fetch_episode_images_names(link)\n",
        "                start = time.time()\n",
        "                print(\": %d images\" % len(names))\n",
        "\n",
        "                if dirs_for_episodes:\n",
        "                    path_for_episode = os.path.join(path, f\"Episode{i}\")\n",
        "                    download_images_fancaps(names, path_for_episode, section, timeout, max_retries)\n",
        "                else:\n",
        "                    download_images_fancaps(names, path, section, timeout, max_retries)\n",
        "\n",
        "                print(\"\\nDownloaded. Time: %.2fs\" % (time.time() - start))\n",
        "\n",
        "\n",
        "def scrape_selected(selected, save_path, ask_for_episodes=False, timeout=10, max_retries=3, dirs_for_episodes=True):\n",
        "    if not selected:\n",
        "        print(\"ERROR! Nothing selected!!!\")\n",
        "        return\n",
        "\n",
        "    print(\"\\tStarting scrapping!\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for category, items in selected.items():\n",
        "        if items:\n",
        "            for item in items:\n",
        "                folder_path = os.path.join(save_path, create_valid_folder_name(item[0]))\n",
        "                url = \"https://fancaps.net\" + item[1]\n",
        "\n",
        "                os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "                print(\"\\nScraping images for %s:\" % item[0])\n",
        "                scrap_time = time.time()\n",
        "                fancaps_scrapper(url, folder_path, ask_for_episodes, timeout, max_retries, dirs_for_episodes)\n",
        "                print(\"Done %s: %.2fs\" % (item[0], time.time() - scrap_time))\n",
        "\n",
        "    print('-'*30)\n",
        "    print(\"\\tDone: %.2fs\" % (time.time() - start_time))\n",
        "\n",
        "scrape_selected(selected_results, image_scrape_path, ask_for_episodes, timeout, max_retries, make_dirs_for_episodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c304a27-65ca-44ed-86c6-3635c033a05c",
      "metadata": {
        "id": "1c304a27-65ca-44ed-86c6-3635c033a05c"
      },
      "source": [
        "## **3Ô∏è‚É£üü® Remove duplicates**\n",
        "Used code from [Dataset Maker colab](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) with some modifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "847dbf29-c1d8-4c88-b4c5-89adac1767d9",
      "metadata": {
        "cellView": "form",
        "id": "847dbf29-c1d8-4c88-b4c5-89adac1767d9"
      },
      "outputs": [],
      "source": [
        "#@title 1 Find duplicates\n",
        "#@markdown This is how similar images should be for marking them to delete. I recommend 0.96 to 0.99 based on your needs:\n",
        "similarity_threshold = 0.98 # @param {type:\"number\"}\n",
        "\n",
        "#@markdown Batch sizes, if you don't know what it is, better don't touch:\n",
        "embedding_batch_size = 200 # @param {type:\"integer\"}\n",
        "similarity_matrix_batch_size = 1000 # @param {type:\"integer\"}\n",
        "\n",
        "#@markdown Clip model name. You can choose another model from fiftyone zoo if you want. Just print its name here.\n",
        "model_name = \"clip-vit-base32-torch\" # @param {type:\"string\"}\n",
        "\n",
        "dataset = fo.Dataset.from_dir(image_scrape_path, dataset_type=fo.types.ImageDirectory)\n",
        "\n",
        "# @markdown This cell will load the scrapped dataset, make embeddings using the selected model, calculate the similarity matrix and find samples to remove.\n",
        "\n",
        "def make_embeddings(model_name, batch_size):\n",
        "    model = foz.load_zoo_model(model_name)\n",
        "    embeddings = dataset.compute_embeddings(model, batch_size=batch_size)\n",
        "\n",
        "    # Unload the model from the GPU to free up memory\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "def calculate_similarity_matrix(embeddings, batch_size):\n",
        "    batch_size = min(embeddings.shape[0], batch_size)\n",
        "    batch_embeddings = np.array_split(embeddings, batch_size)\n",
        "    similarity_matrices = []\n",
        "\n",
        "    # Find the maximum size of the arrays\n",
        "    max_size_x = max(array.shape[0] for array in batch_embeddings)\n",
        "    max_size_y = max(array.shape[1] for array in batch_embeddings)\n",
        "\n",
        "    for batch_embedding in batch_embeddings:\n",
        "        similarity = cosine_similarity(batch_embedding)\n",
        "        # Pad 0 for np.concatenate\n",
        "        padded_array = np.zeros((max_size_x, max_size_y))\n",
        "        padded_array[0:similarity.shape[0], 0:similarity.shape[1]] = similarity\n",
        "        similarity_matrices.append(padded_array)\n",
        "\n",
        "    # Concatenate the padded arrays\n",
        "    similarity_matrix = np.concatenate(similarity_matrices, axis=0)\n",
        "    similarity_matrix = similarity_matrix[0:embeddings.shape[0], 0:embeddings.shape[0]]\n",
        "\n",
        "    similarity_matrix = cosine_similarity(embeddings)\n",
        "    similarity_matrix -= np.identity(len(similarity_matrix))\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "def make_samples(dataset, similarity_matrix, threshold=0.98):\n",
        "    dataset.match(VF(\"max_similarity\") > threshold)\n",
        "    dataset.tags = [\"delete\", \"has_duplicates\"]\n",
        "    id_map = [s.id for s in dataset.select_fields([\"id\"])]\n",
        "    samples_to_remove = set()\n",
        "    samples_to_keep = set()\n",
        "    for idx, sample in enumerate(dataset):\n",
        "      if sample.id not in samples_to_remove:\n",
        "        # Keep the first instance of two duplicates\n",
        "        samples_to_keep.add(sample.id)\n",
        "\n",
        "        dup_idxs = np.where(similarity_matrix[idx] > threshold)[0]\n",
        "        for dup in dup_idxs:\n",
        "            # We kept the first instance so remove all other duplicates\n",
        "            samples_to_remove.add(id_map[dup])\n",
        "        if len(dup_idxs) > 0:\n",
        "            sample.tags.append(\"has_duplicates\")\n",
        "            sample.save()\n",
        "      else:\n",
        "        sample.tags.append(\"delete\")\n",
        "        sample.save()\n",
        "\n",
        "    return samples_to_remove, samples_to_keep\n",
        "\n",
        "embeddings = make_embeddings(model_name, embedding_batch_size)\n",
        "\n",
        "clear_output()\n",
        "print(\"Embeddings calculated!\")\n",
        "\n",
        "similarity_matrix = calculate_similarity_matrix(embeddings, similarity_matrix_batch_size)\n",
        "print(\"Similarity matrix calculated!\")\n",
        "\n",
        "samples_to_remove, samples_to_keep = make_samples(dataset, similarity_matrix, similarity_threshold)\n",
        "print(f\"Remove percentage: {len(samples_to_remove) / (len(samples_to_remove) + len(samples_to_keep)) * 100}\")\n",
        "\n",
        "del embeddings, similarity_matrix, samples_to_remove, samples_to_keep\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "session = None\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a12bf9-1880-4ffc-8658-e55660ee5fe4",
      "metadata": {
        "cellView": "form",
        "id": "46a12bf9-1880-4ffc-8658-e55660ee5fe4"
      },
      "outputs": [],
      "source": [
        "# @title 2 üü© Run the fiftyone app to view marked images\n",
        "# @markdown You can skip this part! It's not important!\n",
        "\n",
        "if session is None:\n",
        "    sidebar_groups = fo.DatasetAppConfig.default_sidebar_groups(dataset)\n",
        "    for group in sidebar_groups[1:]:\n",
        "        group.expanded = False\n",
        "    dataset.app_config.sidebar_groups = sidebar_groups\n",
        "\n",
        "    dataset.save()\n",
        "    session = fo.launch_app(dataset)\n",
        "else:\n",
        "    session.show()\n",
        "\n",
        "# @markdown You can run the fiftyone app to view all scrapped images and manually mark images that you want to delete.\n",
        "# @markdown Input any text in the input to save changes and quit!\n",
        "# @markdown If you don't see the app for more than 2 minutes, maybe your cookies are disabled, or maybe your browser is blocking the session. Try to disable protection.\n",
        "input(\"Input something to quit: \")\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e26cdf9-6835-4f8c-87db-cb2d9c5360d3",
      "metadata": {
        "cellView": "form",
        "id": "4e26cdf9-6835-4f8c-87db-cb2d9c5360d3"
      },
      "outputs": [],
      "source": [
        "# @title 3 Delete duplicates\n",
        "\n",
        "# @markdown Delete all images marked as \"delete\".\n",
        "\n",
        "# @markdown If you want to delete previous images in the folder (if you run this cell before), select this:\n",
        "delete_previous_filtered_images = True # @param {type:\"boolean\"}\n",
        "\n",
        "os.makedirs(filtered_dir, exist_ok=True)\n",
        "\n",
        "if delete_previous_filtered_images:\n",
        "    delete_contents_of_dir(filtered_dir)\n",
        "\n",
        "kys = [s for s in dataset if \"delete\" in s.tags]\n",
        "dataset.delete_samples(kys)\n",
        "n_filtered = len(dataset)\n",
        "dataset.export(export_dir=filtered_dir, dataset_type=fo.types.ImageDirectory)\n",
        "\n",
        "if session is not None:\n",
        "    session.refresh()\n",
        "    fo.close_app()\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(\"Done! Dataset filtered from %d duplicates! Total %d images left!\" % (len(kys), n_filtered))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e662349-b3d1-4381-83ac-f068df412a07",
      "metadata": {
        "id": "6e662349-b3d1-4381-83ac-f068df412a07"
      },
      "source": [
        "## **4Ô∏è‚É£üü® Find similar faces**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26de9d98-ad71-4c1b-a19c-273c26cdc2a1",
      "metadata": {
        "cellView": "form",
        "id": "26de9d98-ad71-4c1b-a19c-273c26cdc2a1"
      },
      "outputs": [],
      "source": [
        "# @title 1 Download face detection and face similarity models\n",
        "\n",
        "# @markdown This cell will download the selected face detection yolov 5 model and my face similarity efficientnet-b0 model from google drive.\n",
        "\n",
        "# @markdown Direct links to the folder with models:\n",
        "# @markdown https://drive.google.com/drive/folders/1Dn4-GgnLOl-co-eICOrOoH6pp9MexBYu?usp=sharing\n",
        "\n",
        "# @markdown Thanks to turdus-merula for download functions, [stack-overflow link](https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url)\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download&confirm=1\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params={\"id\": id}, stream=True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {\"id\": id, \"confirm\": token}\n",
        "        response = session.get(URL, params=params, stream=True)\n",
        "\n",
        "    save_response_content(response, destination)\n",
        "\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith(\"download_warning\"):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:  # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "file_id1 = \"1BmuYn_3pUsWOPqRpjzBUiIBk-XLjsKmY\"\n",
        "file_id2 = \"1gXckAUQpPSojhNehZHmJdh3juuJPmtwI\"\n",
        "file_id3 = \"1j4gnfa3ggsDkp9vfCxh-WiHOFefbOSpK\"\n",
        "\n",
        "if use_yolov_5x_model:\n",
        "    if not os.path.exists(yolov_model_path):\n",
        "        print(\"Donwloading yolov 5x model...\")\n",
        "        download_file_from_google_drive(file_id1, yolov_model_path)\n",
        "elif not os.path.exists(yolov_model_path):\n",
        "    print(\"Donwloading yolov 5s model...\")\n",
        "    download_file_from_google_drive(file_id2, yolov_model_path)\n",
        "\n",
        "if not os.path.exists(similarity_model_path):\n",
        "    print(\"Donwloading similarity model...\")\n",
        "    download_file_from_google_drive(file_id3, similarity_model_path)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6b008d1-9910-4527-a3d1-01cd5d0d7e7e",
      "metadata": {
        "cellView": "form",
        "id": "a6b008d1-9910-4527-a3d1-01cd5d0d7e7e"
      },
      "outputs": [],
      "source": [
        "# @title 2 Define detection params and necessary functions\n",
        "\n",
        "# @markdown Resized image size:\n",
        "image_size = 640 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Do not save faces images smaller than min_face_size pixels.\n",
        "min_face_size = 35 # @param {type:\"number\"}\n",
        "max_aspect_ratio = 6 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Make predicted box smaller / bigger (0.2 -> 20% larger box)\n",
        "adjust_crop_box = 0.2 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown Confidence that it is a face:\n",
        "threshold = 0.5 # @param {type:\"number\"}\n",
        "iou_threshold = 0.5 # @param {type:\"number\"}\n",
        "\n",
        "def visualize_images(dataset, n=10, n_row=5):\n",
        "    if n == 0:\n",
        "        print(\"Error! No images to visualize!\")\n",
        "        return\n",
        "\n",
        "    if n < 0:\n",
        "        print(\"Error! N < 0!\")\n",
        "        return\n",
        "\n",
        "    if n_row <= 0:\n",
        "        print(\"Error! N_ROW <= 0!\")\n",
        "        return\n",
        "\n",
        "    if n != len(dataset):\n",
        "        if n > len(dataset):\n",
        "            n = len(dataset)\n",
        "            print(\"Number of random images is greater than dataset length. Visualizing all %d images\" % len(dataset))\n",
        "        elif n < len(dataset):\n",
        "            print(\"Visualized random %d images\" % n)\n",
        "\n",
        "        random_indices = random.sample(range(len(dataset)), n)\n",
        "    else:\n",
        "        random_indices = range(len(dataset))\n",
        "\n",
        "\n",
        "    drawed = 0\n",
        "    while n:\n",
        "        count = n_row if n > n_row else n\n",
        "        n -= count\n",
        "\n",
        "        plt.figure(figsize=(count * 2, 6))\n",
        "\n",
        "        display_indices = random_indices[drawed:drawed + count]\n",
        "        drawed += count\n",
        "\n",
        "        for i, index in enumerate(display_indices):\n",
        "            image_path = dataset[index]\n",
        "\n",
        "            img = Image.open(image_path)\n",
        "\n",
        "            plt.subplot(1, count, i + 1)\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.subplots_adjust(wspace=.03, hspace=0)\n",
        "\n",
        "\n",
        "def xywh_to_xyxy(xywh):\n",
        "    x_center = xywh[0]\n",
        "    y_center = xywh[1]\n",
        "    width = xywh[2]\n",
        "    height = xywh[3]\n",
        "\n",
        "    x1 = max(0, x_center - width / 2)\n",
        "    y1 = max(0, y_center - height / 2)\n",
        "    x2 = min(1, x_center + width / 2)\n",
        "    y2 = min(1, y_center + height / 2)\n",
        "\n",
        "    return x1, y1, x2, y2\n",
        "\n",
        "\n",
        "def save_cropped(label_dir, image_dir, output_dir, min_face_size=0, max_aspect_ratio=float('inf'), adjust_crop=0):\n",
        "    counter = 0\n",
        "    for label_filename in os.listdir(label_dir):\n",
        "        if label_filename.endswith(\".txt\"):\n",
        "            label_path = os.path.join(label_dir, label_filename)\n",
        "            image_filename_without_ext = os.path.splitext(label_filename)[0]\n",
        "\n",
        "            image_path = None\n",
        "            for ext in supported_image_formats:\n",
        "                potential_image_path = os.path.join(image_dir, f\"{image_filename_without_ext}{ext}\")\n",
        "                if os.path.exists(potential_image_path):\n",
        "                    image_path = potential_image_path\n",
        "                    break\n",
        "\n",
        "            if image_path is None:\n",
        "                print(f\"Image not found for {label_filename}\")\n",
        "                continue\n",
        "\n",
        "            with open(label_path, 'r') as label_file:\n",
        "                lines = label_file.readlines()\n",
        "\n",
        "            for i, line in enumerate(lines, 1):\n",
        "                parts = line.strip().split()\n",
        "                x, y, w, h, conf = map(float, parts[1:])  # Extract coordinates and confidence\n",
        "\n",
        "                x1, y1, x2, y2 = xywh_to_xyxy([x, y, w, h])\n",
        "\n",
        "                box_width, box_height = x2 - x1, y2 - y1\n",
        "                x1 -= box_width * adjust_crop\n",
        "                y1 -= box_height * adjust_crop\n",
        "                x2 += box_width * adjust_crop\n",
        "                y2 += box_height * adjust_crop\n",
        "\n",
        "                # Ensure adjusted coordinates stay within bounds\n",
        "                x1 = max(0, x1)\n",
        "                y1 = max(0, y1)\n",
        "                x2 = min(1, x2)\n",
        "                y2 = min(1, y2)\n",
        "\n",
        "                aspect_ratio = (x2-x1) / (y2-y1)\n",
        "                if aspect_ratio < 1:\n",
        "                    aspect_ratio = 1 / aspect_ratio\n",
        "\n",
        "                if aspect_ratio > max_aspect_ratio:\n",
        "                    continue\n",
        "\n",
        "                # Crop the image using PIL\n",
        "                image = Image.open(image_path)\n",
        "\n",
        "                width, height = image.size\n",
        "                left = int(x1 * width)\n",
        "                upper = int(y1 * height)\n",
        "                right = int(x2 * width)\n",
        "                lower = int(y2 * height)\n",
        "\n",
        "                if min(right - left, lower - upper) < min_face_size:\n",
        "                    continue\n",
        "\n",
        "                cropped_image = image.crop((left, upper, right, lower))\n",
        "\n",
        "                if cropped_image.mode in (\"RGBA\", \"P\"):\n",
        "                    cropped_image = cropped_image.convert(\"RGB\")\n",
        "\n",
        "                # Save cropped image to the output folder\n",
        "                output_filename = f\"{image_filename_without_ext}-{i}-{conf}.jpg\"\n",
        "                output_path = os.path.join(output_dir, output_filename)\n",
        "                cropped_image.save(output_path)\n",
        "\n",
        "                counter += 1\n",
        "\n",
        "    return counter\n",
        "\n",
        "\n",
        "def plot_images_in_folder(folder_path, m=5):\n",
        "    image_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(supported_image_formats)]\n",
        "    visualize_images(image_paths, len(image_paths), m)\n",
        "\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a692b1a-6fbd-4cc7-aa0f-fd4f44154dd2",
      "metadata": {
        "cellView": "form",
        "id": "4a692b1a-6fbd-4cc7-aa0f-fd4f44154dd2",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# @title 3 Find faces on filtered images and save them\n",
        "\n",
        "# @markdown Run yolov5 detect script for finding faces on images. It will create a labels folder with .txt files which contains box coordinates (xywh) and confidence.\n",
        "\n",
        "# @markdown If you want to delete previous images in the folder (if you run this cell before), select this:\n",
        "delete_previous_detections = True # @param {type:\"boolean\"}\n",
        "\n",
        "os.makedirs(faces_dir, exist_ok=True)\n",
        "\n",
        "if delete_previous_detections:\n",
        "    delete_contents_of_dir(faces_dir)\n",
        "\n",
        "# @markdown I used yolov5 models from [yolov5_anime](https://github.com/zymk9/yolov5_anime.git) repo by zymk9 for face detection.\n",
        "\n",
        "if colab:\n",
        "    !python yolov5/detect.py --weights \"{yolov_model_path}\" --source \"{filtered_dir}\" \\\n",
        "            --imgsz {image_size} --nosave --project \"{project_dir}\" --name \"{faces_dir}\" \\\n",
        "            --conf-thres {threshold} --iou-thres {iou_threshold}  --exist-ok --save-txt --save-conf\n",
        "else:\n",
        "    script_runner(f'python yolov5/detect.py --weights \"{yolov_model_path}\" --source \"{filtered_dir}\" '\n",
        "                  f'--imgsz {image_size} --nosave --project \"{project_dir}\" --name \"{faces_dir}\" '\n",
        "                  f'--conf-thres {threshold} --iou-thres {iou_threshold}  --exist-ok --save-txt --save-conf')\n",
        "\n",
        "clear_output()\n",
        "print(\"Detection completed!\")\n",
        "\n",
        "print(\"Saving cropped faces...\")\n",
        "n_cropped = save_cropped(os.path.join(faces_dir, \"labels\"), filtered_dir, faces_dir, min_face_size, max_aspect_ratio, adjust_crop_box)\n",
        "print(\"Done! Total %d faces!\" % n_cropped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e03972f-a76a-417c-969c-aae4b92002cd",
      "metadata": {
        "cellView": "form",
        "id": "1e03972f-a76a-417c-969c-aae4b92002cd",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# @title 4 Choose an example image(s)\n",
        "\n",
        "# @markdown IMPORTANT! Paste links (or paths) to example images (how your desired character looks).\n",
        "# @markdown You can paste multiple links/paths separated by a comma.\n",
        "\n",
        "if colab:\n",
        "    example_images_input = \"\" # @param {type:\"string\"}\n",
        "    example_images = example_images_input.split(',')\n",
        "elif ask_using_inputs:\n",
        "    example_images_input = input(\"Enter example images links or paths separated by comma:\")\n",
        "    example_images = example_images_input.split(',')\n",
        "else:\n",
        "    example_images = [\n",
        "        # If you are not in the colab, it's better to paste links or image paths here.\n",
        "        # If your path contains '\\' char, please add 'r' before \"\". For example, r\"D:\\test.jpg\"\n",
        "        \"https://static.wikia.nocookie.net/cowboybebop/images/7/73/Screen_Shot_2013-12-11_at_12.52.29_PM.png/revision/latest?cb=20140404054920\",\n",
        "        \"https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/89be45f9-c25b-44bc-929d-ecf8d9ccf719/d4jh9ru-250de96b-a7da-4801-9e41-0355bf36a327.jpg/v1/fill/w_638,h_773,q_75,strp/spike_spiegel_by_abnormal_child_d4jh9ru-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9NzczIiwicGF0aCI6IlwvZlwvODliZTQ1ZjktYzI1Yi00NGJjLTkyOWQtZWNmOGQ5Y2NmNzE5XC9kNGpoOXJ1LTI1MGRlOTZiLWE3ZGEtNDgwMS05ZTQxLTAzNTViZjM2YTMyNy5qcGciLCJ3aWR0aCI6Ijw9NjM4In1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmltYWdlLm9wZXJhdGlvbnMiXX0.Y8VP9f-BDhZK5Zq1Ct6TGvxgcSOvo-T5pVnhVEJrOOA\",\n",
        "        \"https://imgix.ranker.com/user_node_img/50088/1001742646/original/the-end-of-a-cat-and-_39_s-life-photo-u1?w=650&q=50&fm=pjpg&fit=crop&crop=faces\"\n",
        "    ]\n",
        "\n",
        "# @markdown If you want to delete previous images in folder (if you run this cell before), select this:\n",
        "delete_previous_examples = True # @param {type:\"boolean\"}\n",
        "\n",
        "os.makedirs(example_orig_img_dir, exist_ok=True)\n",
        "\n",
        "if delete_previous_examples:\n",
        "    delete_contents_of_dir(example_orig_img_dir)\n",
        "\n",
        "def download_example_image(url, path):\n",
        "    filename = ''.join(c if c.isalnum() or c in ['-', '_'] else '_' for c in os.path.basename(url))\n",
        "    if len(filename) > 25:\n",
        "        filename = filename[:25]\n",
        "\n",
        "    file_extension = url.split('.')[-1].lower()\n",
        "    if file_extension not in ['png', 'jpg', 'jpeg']:\n",
        "        file_extension = 'png'  # Default to PNG if extension is not supported\n",
        "\n",
        "    full_path = os.path.join(path, f\"{filename}.{file_extension}\")\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(full_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        return full_path\n",
        "\n",
        "    print(f\"Failed to download image from URL: {url}\")\n",
        "    return None\n",
        "\n",
        "def is_url_or_path(input_string):\n",
        "    url_pattern = r'^https?://.*'\n",
        "\n",
        "    if re.match(url_pattern, input_string):\n",
        "        return 1\n",
        "\n",
        "    if os.path.exists(input_string):\n",
        "        return 2\n",
        "\n",
        "    return None\n",
        "\n",
        "for img in example_images:\n",
        "    img = img.replace('\\\\', '/')\n",
        "    image_type = is_url_or_path(img)\n",
        "    if image_type == 1:\n",
        "        image_path = download_example_image(img, example_orig_img_dir)\n",
        "    elif image_type == 2:\n",
        "        image_path = img\n",
        "        shutil.copy(image_path, example_orig_img_dir)\n",
        "    else:\n",
        "        print(f\"Invalid image: {img}\")\n",
        "        continue\n",
        "\n",
        "print(\"Done!\")\n",
        "\n",
        "# @markdown Visualize your images (rows - how many images will be in one row):\n",
        "rows = 5 # @param {type:\"integer\"}\n",
        "\n",
        "plot_images_in_folder(example_orig_img_dir, rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb3a715a-6238-4ae6-b57e-7647470245ab",
      "metadata": {
        "cellView": "form",
        "id": "cb3a715a-6238-4ae6-b57e-7647470245ab"
      },
      "outputs": [],
      "source": [
        "# @title 5 Detect faces on example images\n",
        "\n",
        "# @markdown If you want to delete previous images in the folder (if you run this cell before), select this:\n",
        "delete_previous_detected_faces = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown If your images are already cropped faces, select this:\n",
        "is_already_cropped = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Resized image size:\n",
        "detect_img_size = 640 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown Confidence that it is a face:\n",
        "detect_threshold = 0.5 # @param {type:\"number\"}\n",
        "detect_iou_threshold = 0.5 # @param {type:\"number\"}\n",
        "\n",
        "os.makedirs(example_faces_dir, exist_ok=True)\n",
        "\n",
        "if delete_previous_detected_faces:\n",
        "    delete_contents_of_dir(example_faces_dir)\n",
        "\n",
        "if is_already_cropped:\n",
        "    file_list = os.listdir(example_orig_img_dir)\n",
        "\n",
        "    for file_name in file_list:\n",
        "        from_path = os.path.join(example_orig_img_dir, file_name)\n",
        "        to_path = os.path.join(example_faces_dir, file_name)\n",
        "        if os.path.isfile(from_path):\n",
        "            shutil.copy(from_path, to_path)\n",
        "else:\n",
        "    if colab:\n",
        "        !python yolov5/detect.py --weights \"{yolov_model_path}\" --source \"{example_orig_img_dir}\" \\\n",
        "        --imgsz {detect_img_size} --nosave --project \"{example_character}\" --name \"{example_faces_dir}\" \\\n",
        "        --conf-thres {detect_threshold} --iou-thres {detect_iou_threshold}  --exist-ok --save-txt --save-conf\n",
        "    else:\n",
        "        script_runner(f'python yolov5/detect.py --weights \"{yolov_model_path}\" --source \"{example_orig_img_dir}\" '\n",
        "                      f'--imgsz {detect_img_size} --nosave --project \"{example_character}\" --name \"{example_faces_dir}\" '\n",
        "                      f'--conf-thres {detect_threshold} --iou-thres {detect_iou_threshold}  --exist-ok --save-txt --save-conf')\n",
        "    n_ex = save_cropped(os.path.join(example_faces_dir, \"labels\"), example_orig_img_dir, example_faces_dir, min_face_size, max_aspect_ratio, adjust_crop_box)\n",
        "    clear_output()\n",
        "    print(\"Total detected %d face(s)!\" % n_ex)\n",
        "    print(\"If some of your faces were not detected, choose a different picture(s)!\")\n",
        "    print(\"If it is already a face, select is_already_cropped, del_previous, and rerun this cell!\")\n",
        "\n",
        "plot_images_in_folder(example_faces_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d7c2a4d-235b-40e9-b15a-7d18e9458fc8",
      "metadata": {
        "cellView": "form",
        "id": "7d7c2a4d-235b-40e9-b15a-7d18e9458fc8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# @title 6 Load face similarity model\n",
        "\n",
        "# @markdown Init efficientnet-b0 siamese network for calculating faces similarity and load downloaded weights.\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.base_model = models.efficientnet_b0()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Get the feature vectors for both images\n",
        "        return self.base_model(x)\n",
        "\n",
        "# Initialize Siamese Network\n",
        "model = SiameseNetwork()\n",
        "\n",
        "# Load the downloaded .pt model weights\n",
        "model.load_state_dict(torch.load(similarity_model_path, map_location=torch.device(device)))\n",
        "model.to(device)\n",
        "\n",
        "clear_output()\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fd18570-ebbf-4d93-b2a6-83ae867f465c",
      "metadata": {
        "cellView": "form",
        "id": "1fd18570-ebbf-4d93-b2a6-83ae867f465c"
      },
      "outputs": [],
      "source": [
        "# @title 7 Define functions for calculating embeddings\n",
        "\n",
        "# @markdown It's a batch size for face images for calculating embeddings vectors.\n",
        "embeddings_batch_size = 32 # @param {type:\"integer\"}\n",
        "\n",
        "# @markdown IMPORTANT! If you change <b>face_image_size</b> it will not work with current model.\n",
        "# @markdown EfficientNet-B0 model requires 224x224 images as input. If you are using other model, you can change it.\n",
        "face_image_size = 224 # @param {type:\"integer\"}\n",
        "\n",
        "def find_images_to_check(images_folder):\n",
        "    images_to_check = []\n",
        "    for root, dirs, files in os.walk(images_folder):\n",
        "        files = [os.path.join(root, file) for file in files if file.endswith(supported_image_formats)]\n",
        "        if len(files):\n",
        "            images_to_check.extend(files)\n",
        "\n",
        "    return images_to_check\n",
        "\n",
        "class ResizeAndPad:\n",
        "    def __init__(self, size, fill_color=(0, 0, 0)):\n",
        "        self.size = size\n",
        "        self.fill_color = fill_color\n",
        "\n",
        "    def __call__(self, image):\n",
        "        # Calculate aspect ratio of the original image\n",
        "        original_width, original_height = image.size\n",
        "        aspect_ratio = original_width / original_height\n",
        "\n",
        "        # Calculate the new dimensions\n",
        "        target_width, target_height = self.size\n",
        "        target_aspect_ratio = target_width / target_height\n",
        "\n",
        "        if target_aspect_ratio > aspect_ratio:\n",
        "            # The target image is wider than the original image, so we need to pad horizontally\n",
        "            new_width = int(target_height * aspect_ratio)\n",
        "            resized_image = image.resize((new_width, target_height))\n",
        "            left_padding = (target_width - new_width) // 2\n",
        "            padded_image = Image.new('RGB', (target_width, target_height), self.fill_color)\n",
        "            padded_image.paste(resized_image, (left_padding, 0))\n",
        "        else:\n",
        "            # The target image is taller than the original image, so we need to pad vertically\n",
        "            new_height = int(target_width / aspect_ratio)\n",
        "            resized_image = image.resize((target_width, new_height))\n",
        "            top_padding = (target_height - new_height) // 2\n",
        "            padded_image = Image.new('RGB', (target_width, target_height), self.fill_color)\n",
        "            padded_image.paste(resized_image, (0, top_padding))\n",
        "\n",
        "        return padded_image\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    ResizeAndPad((face_image_size, face_image_size)),\n",
        "    transforms.Lambda(lambda x: x.convert('RGB') if x.mode == 'RGBA' else x),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, faces_to_check, transform=None):\n",
        "        self.faces_to_check = faces_to_check\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.faces_to_check)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.faces_to_check[idx]\n",
        "\n",
        "        img = Image.open(image_path)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, image_path\n",
        "\n",
        "def make_embeddings(model, loader):\n",
        "    model.eval()\n",
        "\n",
        "    embeddings = []\n",
        "    paths = []\n",
        "\n",
        "    with torch.no_grad(), tqdm(total=len(loader)) as pbar:\n",
        "        for batch_idx, (images, images_paths) in enumerate(loader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            result = model(images).cpu().numpy()\n",
        "\n",
        "            embeddings.extend(result)\n",
        "            paths.extend(images_paths)\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    return embeddings, paths\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "013bf512-cfba-4593-aada-560b2c7ac382",
      "metadata": {
        "cellView": "form",
        "id": "013bf512-cfba-4593-aada-560b2c7ac382"
      },
      "outputs": [],
      "source": [
        "# @title 8 Make embeddings for scrapped faces images\n",
        "# @markdown Find images, create a loader, and make embeddings.\n",
        "\n",
        "embeddings_file = os.path.join(project_dir, \"embeddings.pkl\")\n",
        "\n",
        "if os.path.exists(embeddings_file):\n",
        "    with open(embeddings_file, \"rb\") as file:\n",
        "        saved_data = pickle.load(file)\n",
        "\n",
        "    faces_paths = saved_data[\"faces_paths\"]\n",
        "    faces_embeddings = saved_data[\"faces_embeddings\"]\n",
        "else:\n",
        "    faces_paths = find_images_to_check(faces_dir)\n",
        "    make_embeddings_dataset = CustomDataset(faces_paths, transform)\n",
        "    make_embeddings_loader = torch.utils.data.DataLoader(make_embeddings_dataset, batch_size=embeddings_batch_size)\n",
        "\n",
        "    print(\"Total faces:\", len(faces_paths))\n",
        "    print(\"Total steps:\", len(make_embeddings_loader))\n",
        "\n",
        "    print(\"\\nMaking embeddings...\")\n",
        "    faces_embeddings, faces_paths = make_embeddings(model, make_embeddings_loader)\n",
        "\n",
        "    data_to_save = {\n",
        "        \"faces_paths\": faces_paths,\n",
        "        \"faces_embeddings\": faces_embeddings\n",
        "    }\n",
        "\n",
        "    with open(embeddings_file, \"wb\") as file:\n",
        "        pickle.dump(data_to_save, file)\n",
        "\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "032219bf-8a34-4e70-b6bf-4915046f068b",
      "metadata": {
        "cellView": "form",
        "id": "032219bf-8a34-4e70-b6bf-4915046f068b"
      },
      "outputs": [],
      "source": [
        "# @title 9 Make embeddings for example images\n",
        "# @markdown Get example images, create a loader, and make embeddings.\n",
        "faces_examples = find_images_to_check(example_faces_dir)\n",
        "e_make_embeddings_dataset = CustomDataset(faces_examples, transform)\n",
        "e_make_embeddings_loader = torch.utils.data.DataLoader(e_make_embeddings_dataset, batch_size=embeddings_batch_size)\n",
        "\n",
        "print(\"Total example faces:\", len(faces_examples))\n",
        "print(\"Total steps:\", len(e_make_embeddings_loader))\n",
        "\n",
        "print(\"\\nMaking embeddings...\")\n",
        "e_faces_embeddings, e_faces_paths = make_embeddings(model, e_make_embeddings_loader)\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1be206c4-f548-43d5-8096-88c69f23bd03",
      "metadata": {
        "cellView": "form",
        "id": "1be206c4-f548-43d5-8096-88c69f23bd03"
      },
      "outputs": [],
      "source": [
        "# @title 10 Calculate distances\n",
        "# @markdown Calculate distances between embeddings of detected faces from scrapped images and your example faces.\n",
        "distances = pairwise_distances(faces_embeddings, e_faces_embeddings)\n",
        "print(\"Distances calculated!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efcb559c-6324-4da2-8580-aed2bc65a73c",
      "metadata": {
        "cellView": "form",
        "id": "efcb559c-6324-4da2-8580-aed2bc65a73c"
      },
      "outputs": [],
      "source": [
        "# @title 11 üü© Unload similarity model from GPU VRAM\n",
        "# @markdown Delete model and empty torch cache.\n",
        "\n",
        "# @markdown If you want to make another character from this anime/movie, you can skip this cell.\n",
        "# @markdown When you finish with this character, you will not need to run 1-3, 6-8 steps of this section.\n",
        "\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Model unloaded from GPU VRAM!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50ac644-60eb-46b5-b782-9e40e8643686",
      "metadata": {
        "cellView": "form",
        "id": "a50ac644-60eb-46b5-b782-9e40e8643686"
      },
      "outputs": [],
      "source": [
        "# @title 12 Filter faces images by max faces on them\n",
        "\n",
        "# @markdown Will ignore images where the number of faces is more than this value. Maybe useful if you don't want samples where many people are in your dataset. Leave blank if you don't want to ignore any of the images.\n",
        "max_faces_on_image = 0 # @param {type:\"integer\"}\n",
        "\n",
        "if not max_faces_on_image:\n",
        "    max_faces_on_image = float('inf')\n",
        "\n",
        "def filter_multiple_persons_images_with_embeddings(faces_paths, max_faces):\n",
        "    original_name_counts = {}\n",
        "    to_delete = set()\n",
        "\n",
        "    for i, image_name in enumerate(faces_paths):\n",
        "        original_name = image_name.replace('\\\\','/').split('/')[-1].split('-')[0]  # Extract original image name\n",
        "        if original_name in original_name_counts:\n",
        "            original_name_counts[original_name] += 1\n",
        "            if original_name_counts[original_name] > max_faces:\n",
        "                to_delete.add(original_name)\n",
        "        else:\n",
        "            original_name_counts[original_name] = 1\n",
        "\n",
        "    valid_indices = [i for i, image_name in enumerate(faces_paths) if image_name.replace('\\\\','/').split('/')[-1].split('-')[0] not in to_delete]\n",
        "\n",
        "    return valid_indices, original_name_counts\n",
        "\n",
        "filtered_indices, counts = filter_multiple_persons_images_with_embeddings(faces_paths, max_faces_on_image)\n",
        "\n",
        "print(\"To check:\", len(filtered_indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bb130d0-33da-4f74-a5af-0aeed4771078",
      "metadata": {
        "cellView": "form",
        "id": "4bb130d0-33da-4f74-a5af-0aeed4771078"
      },
      "outputs": [],
      "source": [
        "# @title 13 Find similar faces\n",
        "\n",
        "# @markdown If the pairwise distance of two embedding vectors is lower than this value, the face will be marked as similar.\n",
        "# @markdown This value depends on your character. You can try different values and watch the result.\n",
        "# @markdown You can view your dataset and manually filter images by this threshold in the next cells.\n",
        "threshold = 35 # @param {type:\"number\"}\n",
        "\n",
        "# @markdown If you select this, face should be similar to all your example images. Gives less results.\n",
        "and_method = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Visualize random subset of detected images:\n",
        "visualize = True # @param {type:\"boolean\"}\n",
        "n_images = 50 # @param {type:\"integer\"}\n",
        "n_rows = 10 # @param {type:\"integer\"}\n",
        "\n",
        "def find_similar_images(distances, indices, and_method=False):\n",
        "    similar = []\n",
        "\n",
        "    for i in indices:\n",
        "        distances_row = distances[i]\n",
        "        similar_indices = np.where(distances_row < threshold)[0]\n",
        "        if (not and_method and len(similar_indices)) or (and_method and len(similar_indices) == len(distances_row)):\n",
        "            similar.append(i)\n",
        "\n",
        "    return similar\n",
        "\n",
        "similar_indices = find_similar_images(distances, filtered_indices, and_method)\n",
        "similar_images = [faces_paths[index] for index in similar_indices]\n",
        "print(\"Done! Found %d possible similar images!\" % len(similar_images))\n",
        "\n",
        "if visualize:\n",
        "    visualize_images(similar_images, n_images, n_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d8ad716-8b0c-4f69-b9b9-daccd15aeeba",
      "metadata": {
        "cellView": "form",
        "id": "1d8ad716-8b0c-4f69-b9b9-daccd15aeeba"
      },
      "outputs": [],
      "source": [
        "# @title 14 Create a FiftyOne dataset from faces\n",
        "\n",
        "# @markdown Create a fiftyone dataset and tag similar faces.\n",
        "dataset_similar_faces = fo.Dataset.from_dir(faces_dir, dataset_type=fo.types.ImageDirectory)\n",
        "dataset_similar_faces.tags = [\"similar\"]\n",
        "\n",
        "similar_indices_cp = deepcopy(similar_indices)\n",
        "\n",
        "for i, face in enumerate(faces_paths):\n",
        "    face_path = os.path.abspath(face)\n",
        "    sample = dataset_similar_faces[face_path]\n",
        "    for n, dist in enumerate(distances[i], 1):\n",
        "        sample[f\"Distances {n}\"] = dist\n",
        "    if similar_indices_cp and i == similar_indices_cp[0]:\n",
        "        similar_indices_cp.pop(0)\n",
        "        sample.tags.append(\"similar\")\n",
        "    sample.save()\n",
        "\n",
        "for sample in dataset_similar_faces:\n",
        "    orig_name = sample.filepath.replace('\\\\','/').split('/')[-1].split('-')[0]\n",
        "    sample[\"Faces on image\"] = counts[orig_name]\n",
        "    sample.save()\n",
        "\n",
        "faces_session = None\n",
        "\n",
        "clear_output()\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1202627-f694-4b0b-804a-541a9b2d3641",
      "metadata": {
        "cellView": "form",
        "id": "a1202627-f694-4b0b-804a-541a9b2d3641"
      },
      "outputs": [],
      "source": [
        "# @title 15 üü© Run the Fiftyone app to manually select/deselect wrong faces (optional, but highly recommended)\n",
        "\n",
        "# @markdown Here you can try different values of threshold (marked as distance N), filter your images and manually select and deselect images as similar.\n",
        "\n",
        "# @markdown <b>My recommendations:</b> set your desired max_faces_on_image and find the best distance value where there are many images of your desired character.\n",
        "# @markdown Select all images as similar (tag icon at the top panel, choose similar, press apply).\n",
        "# @markdown Then select the wrong images (press the square box at the top of images), click on the tag icon, deselect a similar tag, and press apply.\n",
        "\n",
        "sidebar_groups = fo.DatasetAppConfig.default_sidebar_groups(dataset_similar_faces)\n",
        "for group in sidebar_groups[1:-1]:\n",
        "    group.expanded = False\n",
        "dataset_similar_faces.app_config.sidebar_groups = sidebar_groups\n",
        "dataset_similar_faces.save()\n",
        "\n",
        "if faces_session is None:\n",
        "    faces_session = fo.launch_app(dataset_similar_faces)\n",
        "else:\n",
        "    faces_session.show()\n",
        "\n",
        "# @markdown Input any text in the input below Fiftyone app to save changes and quit!\n",
        "input(\"Input something to save and quit: \")\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bd063cd-996b-4d58-934b-eddf0354e904",
      "metadata": {
        "cellView": "form",
        "id": "0bd063cd-996b-4d58-934b-eddf0354e904"
      },
      "outputs": [],
      "source": [
        "# @title 16 Save similar faces images separately\n",
        "\n",
        "# @markdown Save all face images tagged as similar!\n",
        "\n",
        "# @markdown If you want to delete previous images in the folder (if you run this cell before), select this:\n",
        "del_previous_saved_faces = True # @param {type:\"boolean\"}\n",
        "\n",
        "os.makedirs(similar_faces_dir, exist_ok=True)\n",
        "\n",
        "if del_previous_saved_faces:\n",
        "    delete_contents_of_dir(similar_faces_dir)\n",
        "\n",
        "view = dataset_similar_faces.match_tags(\"similar\")\n",
        "\n",
        "n_final_similar = len(view)\n",
        "\n",
        "view.export(\n",
        "    export_dir=similar_faces_dir,\n",
        "    dataset_type=fo.types.ImageDirectory\n",
        ")\n",
        "\n",
        "if session is not None:\n",
        "    session.refresh()\n",
        "    fo.close_app()\n",
        "\n",
        "clear_output()\n",
        "print(\"Done! Total: %d images\" % n_final_similar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ecca9b-ae6e-46cb-b7bb-2eddb5095355",
      "metadata": {
        "cellView": "form",
        "id": "72ecca9b-ae6e-46cb-b7bb-2eddb5095355"
      },
      "outputs": [],
      "source": [
        "# @title 17 Save original images with similar faces to the result folder\n",
        "\n",
        "# @markdown Save original scrapped images with your character to the \"result\" folder.\n",
        "\n",
        "# @markdown If you want to delete previous images in the folder (if you run this cell before), select this:\n",
        "delete_previous_results = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown It was the last step! Now you can tag your images using section 5 or zip and export results.\n",
        "# @markdown If you are running this notebook locally, your dataset is already in the workingDir/projectName/result folder, do what you want!\n",
        "\n",
        "os.makedirs(character_results, exist_ok=True)\n",
        "\n",
        "if delete_previous_results:\n",
        "    delete_contents_of_dir(character_results)\n",
        "\n",
        "def copy_images_to_folder(image_paths, destination_folder):\n",
        "    for image_path in image_paths:\n",
        "        image_filename = os.path.basename(image_path)\n",
        "        destination_path = os.path.join(destination_folder, image_filename)\n",
        "        if os.path.exists(image_path):\n",
        "            shutil.copy(image_path, destination_path)\n",
        "        else:\n",
        "            print(\"Error! Image %s doesn't exist!\" % image_path)\n",
        "\n",
        "def remove_confidence(filename):\n",
        "    dash_index = filename.rfind('-')\n",
        "    second_dash_index = filename.rfind('-', 0, dash_index)\n",
        "    last_dot_index = filename.rfind('.')\n",
        "\n",
        "    if second_dash_index >= 0 and last_dot_index > second_dash_index:\n",
        "        return filename[:second_dash_index] + filename[last_dot_index:]\n",
        "\n",
        "    return filename\n",
        "\n",
        "def get_original_images_path(similar_images, orig_dir):\n",
        "    original_images = []\n",
        "    for image_path in similar_images:\n",
        "        original_image_filename = remove_confidence(image_path)\n",
        "        original_image_path = os.path.join(orig_dir, original_image_filename)\n",
        "        original_images.append(original_image_path)\n",
        "\n",
        "    return original_images\n",
        "\n",
        "curated_similar_images = [file for file in os.listdir(similar_faces_dir) if file.endswith(supported_image_formats)]\n",
        "orig_images = get_original_images_path(curated_similar_images, filtered_dir)\n",
        "copy_images_to_folder(orig_images, character_results)\n",
        "\n",
        "print(\"Done! Total: %d images in your dataset!\" % len(orig_images))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b6e4df-5c07-40fb-a274-71c8ec551bfa",
      "metadata": {
        "id": "f7b6e4df-5c07-40fb-a274-71c8ec551bfa"
      },
      "source": [
        "## **5Ô∏è‚É£üü© Tag your images**\n",
        "Used code from  [Dataset Maker colab](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) with some modifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94b88b74-37ad-4f4c-b43a-1470116210e8",
      "metadata": {
        "cellView": "form",
        "id": "94b88b74-37ad-4f4c-b43a-1470116210e8",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#@title 1 Tag images\n",
        "\n",
        "#@markdown We will be using AI to automatically tag your images, specifically [Waifu Diffusion](https://huggingface.co/SmilingWolf/wd-v1-4-swinv2-tagger-v2) in the case of anime and [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) in the case of photos.\n",
        "#@markdown Giving tags/captions to your images allows for much better training. This process should take a couple of minutes. <p>\n",
        "#@markdown Select this to use wd14_tagger and deselect to use blip captions (like for photos).\n",
        "anime_tags = True # @param {type:\"boolean\"}\n",
        "#@markdown **Anime:** The threshold is the minimum level of confidence the tagger must have in order to include a tag. Lower threshold = More tags. Recommended 0.35 to 0.5\n",
        "tag_threshold = 0.35 # @param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "tag_batch_size = 8 # @param {type:\"number\"}\n",
        "blacklist_tags = \"bangs, breasts, multicolored hair, two-tone hair, gradient hair, virtual youtuber, official alternate costume, official alternate hairstyle, official alternate hair length, alternate costume, alternate hairstyle, alternate hair length, alternate hair color\" #@param {type:\"string\"}\n",
        "#@markdown **Photos:** The minimum and maximum length of tokens/words in each caption.\n",
        "max_data_loader_n_workers = 2 # @param {type:\"number\"}\n",
        "caption_min = 10 # @param {type:\"number\"}\n",
        "caption_max = 75 # @param {type:\"number\"}\n",
        "\n",
        "if anime_tags:\n",
        "    if colab:\n",
        "        !python ./kohya-trainer/finetune/tag_images_by_wd14_tagger.py \"{character_results}\" \\\n",
        "                --repo_id=SmilingWolf/wd-v1-4-swinv2-tagger-v2 --general_threshold {tag_threshold} \\\n",
        "                --batch_size {tag_batch_size}\n",
        "    else:\n",
        "        script_runner(f'python ./kohya-trainer/finetune/tag_images_by_wd14_tagger.py \"{character_results}\" '\n",
        "                      f'--repo_id=SmilingWolf/wd-v1-4-swinv2-tagger-v2 --general_threshold {tag_threshold} '\n",
        "                      f'--batch_size {tag_batch_size}')\n",
        "\n",
        "    print(\"Removing underscores and blacklist...\")\n",
        "    blacklisted_tags = [t.strip() for t in blacklist_tags.split(\",\")]\n",
        "    from collections import Counter\n",
        "    top_tags = Counter()\n",
        "    for txt in [f for f in os.listdir(character_results) if f.lower().endswith(\".txt\")]:\n",
        "        with open(os.path.join(character_results, txt), 'r') as f:\n",
        "            tags = [t.strip() for t in f.read().split(\",\")]\n",
        "            tags = [t.replace(\"_\", \" \") if len(t) > 3 else t for t in tags]\n",
        "            tags = [t for t in tags if t not in blacklisted_tags]\n",
        "        top_tags.update(tags)\n",
        "        with open(os.path.join(character_results, txt), 'w') as f:\n",
        "            f.write(\", \".join(tags))\n",
        "\n",
        "    clear_output()\n",
        "    print(f\"\\tTagging complete. Here are the top 50 tags in your dataset:\")\n",
        "    print(\"\\n\".join(f\"{k} ({v})\" for k, v in top_tags.most_common(50)))\n",
        "\n",
        "    del top_tags\n",
        "\n",
        "else:\n",
        "    os.chdir(\"kohya-trainer\")\n",
        "\n",
        "    if colab:\n",
        "        !python ./finetune/make_captions.py \"{character_results}\" \\\n",
        "                --beam_search --max_data_loader_n_workers {max_data_loader_n_workers} \\\n",
        "                --batch_size {tag_batch_size} --min_length {caption_min} \\\n",
        "                --max_length {caption_max} --caption_extension .txt\n",
        "    else:\n",
        "        script_runner(f'python ./finetune/make_captions.py \"{character_results}\" '\n",
        "                      f'--beam_search --max_data_loader_n_workers {max_data_loader_n_workers} '\n",
        "                      f'--batch_size {tag_batch_size} --min_length {caption_min} '\n",
        "                      f'--max_length {caption_max} --caption_extension .txt')\n",
        "\n",
        "    os.chdir(\"../\")\n",
        "\n",
        "    captions = [f for f in os.listdir(character_results) if f.lower().endswith(\".txt\")]\n",
        "    sample = []\n",
        "    for txt in random.sample(captions, min(10, len(captions))):\n",
        "      with open(os.path.join(character_results, txt), 'r') as f:\n",
        "        sample.append(f.read())\n",
        "\n",
        "    clear_output()\n",
        "    print(f\"\\tCaptioning complete. Here are {len(sample)} example captions from your dataset:\")\n",
        "    print(\"\".join(sample))\n",
        "\n",
        "    del sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad608bce-4042-4ae0-b07c-5cc44d774b9f",
      "metadata": {
        "cellView": "form",
        "id": "ad608bce-4042-4ae0-b07c-5cc44d774b9f"
      },
      "outputs": [],
      "source": [
        "#@title 2 Curate your tags\n",
        "\n",
        "#@markdown Modify your dataset's tags. You can run this cell multiple times with different parameters. <p>\n",
        "\n",
        "#@markdown Put an activation tag at the start of every text file. This is useful to make learning better and activate your Lora easier. Set keep_tokens to 1 when training.<p>\n",
        "#@markdown Common tags that are removed such as hair color, etc. will be \"absorbed\" by your activation tag.\n",
        "global_activation_tag = \"global_tag\" #@param {type:\"string\"}\n",
        "remove_tags = \"\" #@param {type:\"string\"}\n",
        "#@markdown &nbsp;\n",
        "\n",
        "#@markdown In this advanced section, you can search text files containing matching tags, and replace them with less/more/different tags. If you select the checkbox below, any extra tags will be put at the start of the file, letting you assign different activation tags to different parts of your dataset. Still, you may want a more advanced tool for this.\n",
        "search_tags = \"\" #@param {type:\"string\"}\n",
        "replace_with = \"\" #@param {type:\"string\"}\n",
        "search_mode = \"OR\" #@param [\"OR\", \"AND\"]\n",
        "new_becomes_activation_tag = False #@param {type:\"boolean\"}\n",
        "#@markdown These may be useful sometimes. Will remove existing activation tags, be careful.\n",
        "sort_alphabetically = False #@param {type:\"boolean\"}\n",
        "remove_duplicates = False #@param {type:\"boolean\"}\n",
        "\n",
        "def split_tags(tagstr):\n",
        "    return [s.strip() for s in tagstr.split(\",\") if s.strip()]\n",
        "\n",
        "activation_tag_list = split_tags(global_activation_tag)\n",
        "remove_tags_list = split_tags(remove_tags)\n",
        "search_tags_list = split_tags(search_tags)\n",
        "replace_with_list = split_tags(replace_with)\n",
        "replace_new_list = [t for t in replace_with_list if t not in search_tags_list]\n",
        "\n",
        "replace_with_list = [t for t in replace_with_list if t not in replace_new_list]\n",
        "replace_new_list.reverse()\n",
        "activation_tag_list.reverse()\n",
        "\n",
        "remove_count = 0\n",
        "replace_count = 0\n",
        "\n",
        "for txt in [f for f in os.listdir(character_results) if f.lower().endswith(\".txt\")]:\n",
        "    with open(os.path.join(character_results, txt), \"r\") as f:\n",
        "        tags = [s.strip() for s in f.read().split(\",\")]\n",
        "\n",
        "    if remove_duplicates:\n",
        "        tags = list(set(tags))\n",
        "    if sort_alphabetically:\n",
        "        tags.sort()\n",
        "\n",
        "    for rem in remove_tags_list:\n",
        "        if rem in tags:\n",
        "            remove_count += 1\n",
        "            tags.remove(rem)\n",
        "\n",
        "    if (\n",
        "        \"AND\" in search_mode\n",
        "        and all(r in tags for r in search_tags_list)\n",
        "        or \"OR\" in search_mode\n",
        "        and any(r in tags for r in search_tags_list)\n",
        "    ):\n",
        "        replace_count += 1\n",
        "        for rem in search_tags_list:\n",
        "            if rem in tags:\n",
        "                tags.remove(rem)\n",
        "        for add in replace_with_list:\n",
        "            if add not in tags:\n",
        "                tags.append(add)\n",
        "        for new in replace_new_list:\n",
        "            if new_becomes_activation_tag:\n",
        "                if new in tags:\n",
        "                    tags.remove(new)\n",
        "                tags.insert(0, new)\n",
        "            else:\n",
        "                if new not in tags:\n",
        "                    tags.append(new)\n",
        "\n",
        "    for act in activation_tag_list:\n",
        "        if act in tags:\n",
        "            tags.remove(act)\n",
        "        tags.insert(0, act)\n",
        "\n",
        "    with open(os.path.join(character_results, txt), \"w\") as f:\n",
        "        f.write(\", \".join(tags))\n",
        "\n",
        "if global_activation_tag:\n",
        "    print(f\"\\nApplied new activation tag(s): {', '.join(activation_tag_list)}\")\n",
        "if remove_tags:\n",
        "    print(f\"Removed {remove_count} tags.\")\n",
        "if search_tags:\n",
        "    print(f\"Replaced in {replace_count} files.\")\n",
        "\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72755dd0-c9cc-44cb-967a-12452e6c2874",
      "metadata": {
        "cellView": "form",
        "id": "72755dd0-c9cc-44cb-967a-12452e6c2874"
      },
      "outputs": [],
      "source": [
        "# @title 3 üü© Analyze tags (show top tags)\n",
        "show_top_tags = 50 #@param {type:\"number\"}\n",
        "\n",
        "top_tags = Counter()\n",
        "\n",
        "for txt in [f for f in os.listdir(character_results) if f.lower().endswith(\".txt\")]:\n",
        "  with open(os.path.join(character_results, txt), 'r') as f:\n",
        "    top_tags.update([s.strip() for s in f.read().split(\",\")])\n",
        "\n",
        "top_tags = Counter(top_tags)\n",
        "print(f\"\\tTop {show_top_tags} tags:\")\n",
        "for k, v in top_tags.most_common(show_top_tags):\n",
        "  print(f\"{k} ({v})\")\n",
        "\n",
        "del top_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef1a76fb-8596-4b3d-a0bc-af1ce22aeed3",
      "metadata": {
        "id": "ef1a76fb-8596-4b3d-a0bc-af1ce22aeed3",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## **6Ô∏è‚É£üü© Zip results**\n",
        "\n",
        "Don't forget to run the first section if you are working in a new runtime!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b7e4e0-d624-4dcd-b081-1ffbf23d54d0",
      "metadata": {
        "cellView": "form",
        "id": "85b7e4e0-d624-4dcd-b081-1ffbf23d54d0"
      },
      "outputs": [],
      "source": [
        "# @title 1 Zip your result folder\n",
        "\n",
        "# @markdown if you rerun some cells to made dataset of more then one characters, you can zip all characters in result folder\n",
        "zip_all_characters = False #@param {type:\"boolean\"}\n",
        "\n",
        "def zip_folder(folder_path, output_path):\n",
        "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, folder_path)\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "# @markdown Filename of your zip file:\n",
        "zip_file_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown If you want to save results to google drive write <b>drive/My Drive/</b>.\n",
        "# @markdown Don't forget to connect this notebook to your google drive (run cell in the second section).\n",
        "# @markdown If you want to save to default path: <b>{working_dir}/{project_name}/zif_file_name.zip</b> leave field blank.\n",
        "zip_output_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if not zip_file_name:\n",
        "    zip_file_name = character_name + \".zip\"\n",
        "\n",
        "if not zip_output_path:\n",
        "    zip_output_path = project_dir\n",
        "\n",
        "os.makedirs(zip_output_path, exist_ok=True)\n",
        "\n",
        "zip_file = os.path.join(zip_output_path, zip_file_name)\n",
        "\n",
        "if zip_all_characters:\n",
        "    zip_folder(result_dir, zip_file)\n",
        "else:\n",
        "    zip_folder(character_results, zip_file)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UoukOChOj0IP",
      "metadata": {
        "cellView": "form",
        "id": "UoukOChOj0IP"
      },
      "outputs": [],
      "source": [
        "# @title 2 Zip custom folder\n",
        "\n",
        "def zip_folder(folder_path, output_path):\n",
        "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, folder_path)\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "# @markdown Type folder path to zip (you can copy desired path from 1.5 step):\n",
        "folder_to_zip = \"\" #@param {type:\"string\"}\n",
        "# @markdown Filename of your zip file:\n",
        "zip_file_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown If you want to save results to google drive write <b>drive/My Drive/</b>.\n",
        "# @markdown Don't forget to connect this notebook to your google drive (run cell in the second section).\n",
        "# @markdown If you want to save to default path: <b>{working_dir}/{project_name}/zif_file_name.zip</b> leave field blank.\n",
        "zip_output_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if not zip_file_name:\n",
        "    zip_file_name = character_name + \".zip\"\n",
        "\n",
        "if not zip_output_path:\n",
        "    zip_output_path = project_dir\n",
        "\n",
        "os.makedirs(zip_output_path, exist_ok=True)\n",
        "\n",
        "zip_file = os.path.join(zip_output_path, zip_file_name)\n",
        "\n",
        "if folder_to_zip:\n",
        "    zip_folder(folder_to_zip, zip_file)\n",
        "    print(\"Done!\")\n",
        "else:\n",
        "    print(\"Choose folder to zip!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0Swg8RlWGxXU",
      "metadata": {
        "cellView": "form",
        "id": "0Swg8RlWGxXU"
      },
      "outputs": [],
      "source": [
        "# @title 3 Zip entire project\n",
        "def zip_folder(folder_path, output_path):\n",
        "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, folder_path)\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "# @markdown Filename of your zip file:\n",
        "zip_file_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown If you want to save results to google drive write <b>drive/My Drive/</b>.\n",
        "# @markdown Don't forget to connect this notebook to your google drive (run cell in the second section).\n",
        "# @markdown If you want to save to default path: <b>{working_dir}/{project_name}/zif_file_name.zip</b> leave field blank.\n",
        "zip_output_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if not zip_file_name:\n",
        "    zip_file_name = \"project.zip\"\n",
        "\n",
        "if not zip_output_path:\n",
        "    zip_output_path = project_dir\n",
        "\n",
        "os.makedirs(zip_output_path, exist_ok=True)\n",
        "\n",
        "zip_file = os.path.join(zip_output_path, zip_file_name)\n",
        "zip_folder(project_dir, zip_file)\n",
        "\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4237acf-1df5-4195-ad7f-d1d06cb75e37",
      "metadata": {
        "cellView": "form",
        "id": "e4237acf-1df5-4195-ad7f-d1d06cb75e37"
      },
      "outputs": [],
      "source": [
        "# @title 4 Download the zip file to your device (only if colab)\n",
        "\n",
        "# @markdown Leave blank if you want to download the zip archive created by executing one of the last two cells. Or write a path two your zip file.\n",
        "zip_file_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if not zip_file_path:\n",
        "    zip_file_path = zip_file\n",
        "\n",
        "if colab:\n",
        "    files.download(zip_file_path)\n",
        "    print(\"Download should start!\")\n",
        "else:\n",
        "    print(\"You are not in a colab! If it's wrong, please select colab at first cell!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_evfwH3-GYSz",
      "metadata": {
        "id": "_evfwH3-GYSz",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## **7Ô∏è‚É£üü© Unzip acrhive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6CcIjWfGGoIK",
      "metadata": {
        "cellView": "form",
        "id": "6CcIjWfGGoIK"
      },
      "outputs": [],
      "source": [
        "# @title Unzip zip file\n",
        "\n",
        "# @markdown Write a path to your zip file:\n",
        "path_to_zip_file = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown Leave blank to extract to project dir or enter extraction path:\n",
        "extracted_folder_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# @markdown May be useful for some colab users! You can upload your zip file directly in colab.\n",
        "# @markdown Click on the \"Files\" icon on the left sidebar (it looks like a folder), click on the \"Upload\" button and select the zip file from your local device.\n",
        "# @markdown Path to zip file will be <b>name_of_file.zip</b>. If your file is in the root folder in google drive, path_to_zip_file will be <b>drive/My Drive/name_of_file.zip</b>.\n",
        "\n",
        "if path_to_zip_file:\n",
        "    if not extracted_folder_path:\n",
        "        extracted_folder_path = project_dir\n",
        "\n",
        "    os.makedirs(extracted_folder_path, exist_ok=True)\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_folder_path)\n",
        "\n",
        "    print(\"Done!\")\n",
        "else:\n",
        "    print(\"You should fill path_to_zip_file variable!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e38afaea-4f86-48b8-b9c9-6025c30c0dac",
      "metadata": {
        "id": "e38afaea-4f86-48b8-b9c9-6025c30c0dac",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## **8Ô∏è‚É£üü© Deleting options**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e5abf09-3924-4606-a5d7-2d928b0141a9",
      "metadata": {
        "cellView": "form",
        "id": "4e5abf09-3924-4606-a5d7-2d928b0141a9"
      },
      "outputs": [],
      "source": [
        "#@title 1 Delete all tags (.txt files) in result folder\n",
        "def del_all_files_with_extension(dir, extension):\n",
        "    files = os.listdir(dir)\n",
        "    for file in files:\n",
        "        if file.endswith(extension):\n",
        "            file_path = os.path.join(dir, file)\n",
        "            os.remove(file_path)\n",
        "\n",
        "del_all_files_with_extension(character_results, \".txt\")\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b5e028-479b-45c7-8ab4-fe5a46674160",
      "metadata": {
        "cellView": "form",
        "id": "80b5e028-479b-45c7-8ab4-fe5a46674160"
      },
      "outputs": [],
      "source": [
        "#@title 2 Delete project\n",
        "\n",
        "delete_contents_of_dir(project_dir)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06900d64-1453-4634-9cfc-b18be1787719",
      "metadata": {
        "cellView": "form",
        "id": "06900d64-1453-4634-9cfc-b18be1787719"
      },
      "outputs": [],
      "source": [
        "#@title 3 Delete all content in the working dir (Don't run if your path is \"./\" or \"drive/My Drive\")\n",
        "\n",
        "if working_dir == os.path.abspath(os.getcwd()) or working_dir == os.path.abspath(os.path.join(os.getcwd(), \"drive/My Drive\")):\n",
        "    print(\"Don't run this cell! Read above!\")\n",
        "else:\n",
        "    delete_contents_of_dir(working_dir)\n",
        "    print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RpZFNNBy2uNn",
      "metadata": {
        "id": "RpZFNNBy2uNn"
      },
      "source": [
        "## **‚ú≥Ô∏è Give feedback**\n",
        "\n",
        "I worked on this project for three weeks. Most of the time was spent preparing the dataset and training the model to determine if two anime faces are the same. If you like something, something is missing, or you think this project is not working well, write to me (I left links where you can contact me).\n",
        "\n",
        "What I want to do:\n",
        "1. Improve the current model to determine if two faces are the same. The model is often wrong. Most likely due to insufficient data for training. However, since the current model is already able to detect the same faces by itself, it will be much easier to increase the dataset than to collect it manually.\n",
        "2. Try to increase the speed of downloading pictures, as this is the longest process. Now I'm working on it. If you have any ideas about how it can be faster - write to me.\n",
        "4. Ability to recognize and identify identical real faces. There are already a lot of such repositories on Git Hub (for example, [this one](https://github.com/ageitgey/face_recognition))."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "a229aead-133b-4dd3-b806-12cdbecd2313",
        "ae60d041-1767-41ef-90fe-5d971ea72e7d",
        "1c304a27-65ca-44ed-86c6-3635c033a05c",
        "6e662349-b3d1-4381-83ac-f068df412a07",
        "f7b6e4df-5c07-40fb-a274-71c8ec551bfa",
        "ef1a76fb-8596-4b3d-a0bc-af1ce22aeed3",
        "_evfwH3-GYSz",
        "e38afaea-4f86-48b8-b9c9-6025c30c0dac"
      ],
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
